{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ecec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts relative paths to absolute ones\n",
    "ROOT_TRAIN_DATA_FOLDER ='../data/raw/Data_Challenge_PHM2023_training_data'\n",
    "ROOT_VAL_DATA_FOLDER = 'data/raw/B - PHM America 2023 - Dataset/Data_Challenge_PHM2023_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8758f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57cf438",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce10969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARICAMENTO DATASET ===\n",
      "Conteggio file in corso...\n",
      "Trovati 2016 file .txt da processare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing dataset: 100%|██████████| 2016/2016 [09:22<00:00,  3.58file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinamento dataset...\n",
      "Dataset caricato: 2016 file processati\n",
      "Health levels disponibili: [0, 1, 2, 3, 4, 6, 8]\n",
      "Condizioni operative (rpm): [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1200, 2100, 2700, 3000, 3600]\n",
      "Condizioni operative (torque): [50, 100, 200, 300, 400, 500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "etichetta",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "health_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "velocita",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "torque",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "horizontal_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "axial_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "vertical_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tachometer_signal",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sampling_rate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_samples",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "descrizione",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a90f3521-0bf4-4a84-a280-230e0c5d627a",
       "rows": [
        [
         "0",
         "V100_50N_1.txt",
         "0",
         "0",
         "100",
         "50",
         "1",
         "[-0.46260182 -0.71244899 -0.55092912 ... -0.02406671 -0.05222724\n  0.04329526]",
         "[-0.49911102 -0.73771904 -0.56997536 ...  0.02012924 -0.00494402\n  0.07733866]",
         "[-0.42549879 -0.81448494 -0.54298996 ...  0.00084353 -0.03639214\n  0.11351455]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         "Healthy"
        ],
        [
         "1",
         "V100_50N_2.txt",
         "0",
         "0",
         "100",
         "50",
         "2",
         "[ 0.08373726 -0.01240552 -0.05421212 ...  0.08386131 -0.11909299\n  0.08869946]",
         "[ 0.04308364 -0.0522654  -0.09993992 ...  0.0705112  -0.13254694\n  0.0815764 ]",
         "[ 0.09495697 -0.06374649 -0.13363867 ...  0.13954336 -0.19991574\n  0.13315666]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         "Healthy"
        ],
        [
         "2",
         "V100_50N_3.txt",
         "0",
         "0",
         "100",
         "50",
         "3",
         "[-0.06376437  0.09676305 -0.04503204 ... -0.01873233  0.0525994\n -0.10085687]",
         "[-0.07804495  0.07745638 -0.0649786  ...  0.00659203  0.0839307\n -0.06886319]",
         "[-0.09857208  0.15340129 -0.08254508 ...  0.00361511  0.14231494\n -0.111948  ]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         "Healthy"
        ],
        [
         "3",
         "V100_50N_4.txt",
         "0",
         "0",
         "100",
         "50",
         "4",
         "[ 0.07418501 -0.03634817 -0.08572214 ...  0.08783108 -0.06711386\n  0.09155273]",
         "[ 0.06933405 -0.03107672 -0.07251236 ...  0.06686204 -0.0981742\n  0.06709747]",
         "[ 0.15195525 -0.01518347 -0.08507566 ...  0.13086709 -0.14532754\n  0.15496784]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         "Healthy"
        ],
        [
         "4",
         "V100_50N_5.txt",
         "0",
         "0",
         "100",
         "50",
         "5",
         "[-0.02816053  0.04416365  0.0573135  ... -0.11164968  0.10705963\n -0.09266923]",
         "[-0.06439003  0.02001153  0.03849276 ... -0.08887472  0.13172293\n -0.07733866]",
         "[-0.07965299  0.03108997  0.0639875  ... -0.19389056  0.16412613\n -0.15496784]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         "Healthy"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>etichetta</th>\n",
       "      <th>health_level</th>\n",
       "      <th>velocita</th>\n",
       "      <th>torque</th>\n",
       "      <th>rep</th>\n",
       "      <th>horizontal_acceleration</th>\n",
       "      <th>axial_acceleration</th>\n",
       "      <th>vertical_acceleration</th>\n",
       "      <th>tachometer_signal</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>descrizione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V100_50N_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4626018245, -0.7124489885, -0.5509291238, ...</td>\n",
       "      <td>[-0.4991110174, -0.7377190438, -0.5699753646, ...</td>\n",
       "      <td>[-0.4254987892, -0.814484938, -0.5429899587, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V100_50N_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.08373725705, -0.01240551956, -0.05421212049...</td>\n",
       "      <td>[0.04308363971, -0.05226539899, -0.09993991833...</td>\n",
       "      <td>[0.0949569657, -0.06374649093, -0.1336386738, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V100_50N_3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.06376437055, 0.09676305259, -0.04503203601...</td>\n",
       "      <td>[-0.07804495389, 0.07745637958, -0.06497860415...</td>\n",
       "      <td>[-0.0985720786, 0.153401291, -0.08254507805, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V100_50N_4.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.07418500699, -0.03634817232, -0.08572214018...</td>\n",
       "      <td>[0.06933405406, -0.03107672372, -0.07251235535...</td>\n",
       "      <td>[0.1519552459, -0.01518347421, -0.08507565708,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V100_50N_5.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.02816052941, 0.04416364964, 0.05731350038,...</td>\n",
       "      <td>[-0.06439002983, 0.02001152664, 0.03849276007,...</td>\n",
       "      <td>[-0.07965298772, 0.031089971, 0.06398749846, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name etichetta  health_level  velocita  torque  rep  \\\n",
       "0  V100_50N_1.txt         0             0       100      50    1   \n",
       "1  V100_50N_2.txt         0             0       100      50    2   \n",
       "2  V100_50N_3.txt         0             0       100      50    3   \n",
       "3  V100_50N_4.txt         0             0       100      50    4   \n",
       "4  V100_50N_5.txt         0             0       100      50    5   \n",
       "\n",
       "                             horizontal_acceleration  \\\n",
       "0  [-0.4626018245, -0.7124489885, -0.5509291238, ...   \n",
       "1  [0.08373725705, -0.01240551956, -0.05421212049...   \n",
       "2  [-0.06376437055, 0.09676305259, -0.04503203601...   \n",
       "3  [0.07418500699, -0.03634817232, -0.08572214018...   \n",
       "4  [-0.02816052941, 0.04416364964, 0.05731350038,...   \n",
       "\n",
       "                                  axial_acceleration  \\\n",
       "0  [-0.4991110174, -0.7377190438, -0.5699753646, ...   \n",
       "1  [0.04308363971, -0.05226539899, -0.09993991833...   \n",
       "2  [-0.07804495389, 0.07745637958, -0.06497860415...   \n",
       "3  [0.06933405406, -0.03107672372, -0.07251235535...   \n",
       "4  [-0.06439002983, 0.02001152664, 0.03849276007,...   \n",
       "\n",
       "                               vertical_acceleration  \\\n",
       "0  [-0.4254987892, -0.814484938, -0.5429899587, -...   \n",
       "1  [0.0949569657, -0.06374649093, -0.1336386738, ...   \n",
       "2  [-0.0985720786, 0.153401291, -0.08254507805, -...   \n",
       "3  [0.1519552459, -0.01518347421, -0.08507565708,...   \n",
       "4  [-0.07965298772, 0.031089971, 0.06398749846, -...   \n",
       "\n",
       "                                   tachometer_signal  sampling_rate  duration  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "\n",
       "   num_samples descrizione  \n",
       "0       246784     Healthy  \n",
       "1       246784     Healthy  \n",
       "2       246784     Healthy  \n",
       "3       246784     Healthy  \n",
       "4       246784     Healthy  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def parse_vibration_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Parsa il dataset di vibrazione e crea un DataFrame pandas con una riga per ogni file.\n",
    "    Ogni riga contiene gli array completi delle serie temporali di vibrazione.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Percorso alla cartella principale del dataset\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con colonne etichetta, velocità, torque, rep e array di dati di vibrazione (una riga per file)\n",
    "    \"\"\"\n",
    "\n",
    "    data_list = []\n",
    "    \n",
    "    # Prima passata: conta il numero totale di file .txt\n",
    "    print(\"Conteggio file in corso...\")\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        total_files += sum(1 for file in files if file.endswith('.txt'))\n",
    "    \n",
    "    print(f\"Trovati {total_files} file .txt da processare\")\n",
    "\n",
    "    # Seconda passada: processa i file con progress bar\n",
    "    with tqdm(total=total_files, desc=\"Parsing dataset\", unit=\"file\") as pbar:\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    folder_name = os.path.basename(root)\n",
    "                    if 'Pitting_degradation_level_' in folder_name:\n",
    "                        etichetta_full = folder_name.replace('Pitting_degradation_level_', '')\n",
    "                        if '(' in etichetta_full:\n",
    "                            etichetta = etichetta_full.split('(')[0].strip()\n",
    "                            descrizione = etichetta_full.split('(')[1].replace(')', '').strip()\n",
    "                        else:\n",
    "                            etichetta = etichetta_full.strip()\n",
    "                            descrizione = None\n",
    "                    else:\n",
    "                        etichetta = folder_name\n",
    "                        descrizione = None\n",
    "\n",
    "                    # ERRORE CORRETTO: regex pattern per V100_200N_2.txt\n",
    "                    pattern = r'V(\\d+)_(\\d+)N_(\\d+)\\.txt'\n",
    "                    match = re.search(pattern, file)\n",
    "\n",
    "                    if match:\n",
    "                        velocita = int(match.group(1))\n",
    "                        torque = int(match.group(2))\n",
    "                        rep = int(match.group(3))\n",
    "\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        try:\n",
    "                            # Carica tutti i dati del file una volta sola\n",
    "                            data = np.loadtxt(file_path)\n",
    "                            \n",
    "                            # Calcola informazioni aggiuntive sui dati\n",
    "                            sampling_rate = 20480  # Hz come specificato nella documentazione\n",
    "                            duration = len(data) / sampling_rate\n",
    "                            \n",
    "                            # Crea un record per l'intero file\n",
    "                            record = {\n",
    "                                'file_name': file,\n",
    "                                'etichetta': etichetta,\n",
    "                                'health_level': int(etichetta) if etichetta.isdigit() else etichetta,\n",
    "                                'velocita': velocita,\n",
    "                                'torque': torque,\n",
    "                                'rep': rep,\n",
    "                                'horizontal_acceleration': data[:, 0],  # Array completo\n",
    "                                'axial_acceleration': data[:, 1],       # Array completo\n",
    "                                'vertical_acceleration': data[:, 2],    # Array completo\n",
    "                                'tachometer_signal': data[:, 3],        # Array completo\n",
    "                                'sampling_rate': sampling_rate,\n",
    "                                'duration': duration,\n",
    "                                'num_samples': len(data),\n",
    "                                'descrizione': descrizione\n",
    "                            }\n",
    "                            # ERRORE CORRETTO: aggiungi record invece di data\n",
    "                            data_list.append(record)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            tqdm.write(f\"Errore nel leggere il file {file_path}: {e}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        tqdm.write(f\"Nome file non riconosciuto: {file}\")\n",
    "                    \n",
    "                    # Aggiorna la progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    if not df.empty:\n",
    "        print(\"\\nOrdinamento dataset...\")\n",
    "        df = df.sort_values(['health_level', 'velocita', 'torque', 'rep']).reset_index(drop=True)\n",
    "        print(f\"Dataset caricato: {len(df)} file processati\")\n",
    "        print(f\"Health levels disponibili: {sorted(df['health_level'].unique())}\")\n",
    "        print(f\"Condizioni operative (rpm): {sorted(df['velocita'].unique())}\")\n",
    "        print(f\"Condizioni operative (torque): {sorted(df['torque'].unique())}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_signal_features(df, signal_column):\n",
    "    \"\"\"\n",
    "    Estrae features statistiche e nel dominio della frequenza da una colonna di segnali.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con i dati\n",
    "        signal_column (str): Nome della colonna contenente gli array dei segnali\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con features estratte\n",
    "    \"\"\"\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    # Progress bar per l'estrazione delle features\n",
    "    with tqdm(total=len(df), desc=f\"Estraendo features da {signal_column}\", unit=\"segnale\") as pbar:\n",
    "        for idx, row in df.iterrows():\n",
    "            signal = row[signal_column]\n",
    "            \n",
    "            # Features statistiche nel dominio del tempo\n",
    "            features = {\n",
    "                f'{signal_column}_mean': np.mean(signal),\n",
    "                f'{signal_column}_std': np.std(signal),\n",
    "                f'{signal_column}_rms': np.sqrt(np.mean(signal**2)),\n",
    "                f'{signal_column}_peak': np.max(np.abs(signal)),\n",
    "                f'{signal_column}_peak_to_peak': np.ptp(signal),\n",
    "                f'{signal_column}_skewness': stats.skew(signal),\n",
    "                f'{signal_column}_kurtosis': stats.kurtosis(signal),\n",
    "                f'{signal_column}_crest_factor': np.max(np.abs(signal)) / np.sqrt(np.mean(signal**2)),\n",
    "            }\n",
    "            \n",
    "            # Features nel dominio della frequenza\n",
    "            sampling_rate = row['sampling_rate']\n",
    "            fft_vals = np.abs(fft(signal))\n",
    "            freqs = fftfreq(len(signal), 1/sampling_rate)\n",
    "            \n",
    "            # Considera solo le frequenze positive\n",
    "            positive_freq_idx = freqs > 0\n",
    "            fft_positive = fft_vals[positive_freq_idx]\n",
    "            freqs_positive = freqs[positive_freq_idx]\n",
    "            \n",
    "            # Trova la frequenza dominante\n",
    "            dominant_freq_idx = np.argmax(fft_positive)\n",
    "            features[f'{signal_column}_dominant_freq'] = freqs_positive[dominant_freq_idx]\n",
    "            features[f'{signal_column}_dominant_magnitude'] = fft_positive[dominant_freq_idx]\n",
    "            \n",
    "            # Features spettrali\n",
    "            total_power = np.sum(fft_positive**2)\n",
    "            features[f'{signal_column}_spectral_centroid'] = np.sum(freqs_positive * fft_positive**2) / total_power\n",
    "            features[f'{signal_column}_spectral_rolloff'] = freqs_positive[np.where(np.cumsum(fft_positive**2) >= 0.85 * total_power)[0][0]]\n",
    "            \n",
    "            features_list.append(features)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "def extract_all_features(df):\n",
    "    \"\"\"\n",
    "    Estrae tutte le features da tutti i segnali di accelerazione con progress bar complessiva.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con i dati grezzi\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame completo con tutte le features\n",
    "    \"\"\"\n",
    "    print(\"Iniziando estrazione features da tutti i segnali...\")\n",
    "    \n",
    "    # Estrai features da tutti i segnali di accelerazione\n",
    "    horizontal_features = extract_signal_features(df, 'horizontal_acceleration')\n",
    "    axial_features = extract_signal_features(df, 'axial_acceleration')\n",
    "    vertical_features = extract_signal_features(df, 'vertical_acceleration')\n",
    "\n",
    "    print(\"Combinando tutte le features...\")\n",
    "    # Combina tutte le features\n",
    "    features_df = pd.concat([\n",
    "        df[['file_name', 'health_level', 'velocita', 'torque', 'rep']],\n",
    "        horizontal_features,\n",
    "        axial_features, \n",
    "        vertical_features\n",
    "    ], axis=1)\n",
    "\n",
    "    print(f\"Features dataset completato! Shape: {features_df.shape}\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "# Carica il dataset\n",
    "print(\"=== CARICAMENTO DATASET ===\")\n",
    "df = parse_vibration_dataset(ROOT_TRAIN_DATA_FOLDER)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "895075ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/processed/train_data_walt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967773ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ESTRAZIONE FEATURES ===\n",
      "Iniziando estrazione features da tutti i segnali...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estraendo features da horizontal_acceleration: 100%|██████████| 2016/2016 [01:04<00:00, 31.24segnale/s]\n",
      "Estraendo features da axial_acceleration: 100%|██████████| 2016/2016 [01:04<00:00, 31.06segnale/s]\n",
      "Estraendo features da vertical_acceleration: 100%|██████████| 2016/2016 [01:01<00:00, 32.53segnale/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinando tutte le features...\n",
      "Features dataset completato! Shape: (2016, 41)\n",
      "\n",
      "=== COMPLETATO ===\n",
      "Dataset finale: 2016 campioni, 41 features\n",
      "Colonne delle features: ['horizontal_acceleration_mean', 'horizontal_acceleration_std', 'horizontal_acceleration_rms', 'horizontal_acceleration_peak', 'horizontal_acceleration_peak_to_peak', 'horizontal_acceleration_skewness', 'horizontal_acceleration_kurtosis', 'horizontal_acceleration_crest_factor', 'horizontal_acceleration_dominant_freq', 'horizontal_acceleration_dominant_magnitude', 'horizontal_acceleration_spectral_centroid', 'horizontal_acceleration_spectral_rolloff', 'axial_acceleration_mean', 'axial_acceleration_std', 'axial_acceleration_rms', 'axial_acceleration_peak', 'axial_acceleration_peak_to_peak', 'axial_acceleration_skewness', 'axial_acceleration_kurtosis', 'axial_acceleration_crest_factor', 'axial_acceleration_dominant_freq', 'axial_acceleration_dominant_magnitude', 'axial_acceleration_spectral_centroid', 'axial_acceleration_spectral_rolloff', 'vertical_acceleration_mean', 'vertical_acceleration_std', 'vertical_acceleration_rms', 'vertical_acceleration_peak', 'vertical_acceleration_peak_to_peak', 'vertical_acceleration_skewness', 'vertical_acceleration_kurtosis', 'vertical_acceleration_crest_factor', 'vertical_acceleration_dominant_freq', 'vertical_acceleration_dominant_magnitude', 'vertical_acceleration_spectral_centroid', 'vertical_acceleration_spectral_rolloff']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== ESTRAZIONE FEATURES ===\")\n",
    "# Estrai tutte le features\n",
    "features_df = extract_all_features(df)\n",
    "\n",
    "print(f\"\\n=== COMPLETATO ===\")\n",
    "print(f\"Dataset finale: {features_df.shape[0]} campioni, {features_df.shape[1]} features\")\n",
    "print(f\"Colonne delle features: {[col for col in features_df.columns if col not in ['file_name', 'health_level', 'velocita', 'torque', 'rep']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366156de",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6122223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, resample\n",
    "import numpy as np\n",
    "\n",
    "def butter_lowpass_filter(signal, cutoff, fs, order=5):\n",
    "    \"\"\"Applica un filtro passa basso Butterworth.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def preprocess_and_resample(signal, fs=20480, target_length=61440, cutoff=5000, filter_order=5):\n",
    "    \"\"\"\n",
    "    Filtra e fa il resample di un segnale ad una lunghezza fissa.\n",
    "    \"\"\"\n",
    "    filtered = butter_lowpass_filter(signal, cutoff, fs, order=filter_order)\n",
    "    return resample(filtered, target_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb39fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vibration_dataframe(df, target_length=61440, cutoff=5000):\n",
    "    \"\"\"\n",
    "    Applica filtraggio e resample a tutti i segnali accelerometrici e tachimetro nel DataFrame.\n",
    "    Ritorna un nuovo DataFrame con colonne preprocessate.\n",
    "    \"\"\"\n",
    "    processed_records = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocessing\"):\n",
    "        try:\n",
    "            record = {\n",
    "                'file_name': row['file_name'],\n",
    "                'etichetta': row['etichetta'],\n",
    "                'health_level': row['health_level'],\n",
    "                'velocita': row['velocita'],\n",
    "                'torque': row['torque'],\n",
    "                'rep': row['rep'],\n",
    "                'sampling_rate': row['sampling_rate'],\n",
    "                'descrizione': row['descrizione'],\n",
    "                'duration': row['duration'],\n",
    "                'num_samples': row['num_samples']\n",
    "            }\n",
    "\n",
    "            # Applica filtro + resample ai 4 segnali\n",
    "            record['horizontal_acceleration'] = preprocess_and_resample(\n",
    "                row['horizontal_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['axial_acceleration'] = preprocess_and_resample(\n",
    "                row['axial_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['vertical_acceleration'] = preprocess_and_resample(\n",
    "                row['vertical_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['tachometer_signal'] = preprocess_and_resample(\n",
    "                row['tachometer_signal'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "\n",
    "            processed_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Errore durante il preprocessing del file {row['file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(processed_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41af7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   1%|          | 16/2016 [00:20<42:49,  1.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_vibration_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead\n",
      "Cell \u001b[1;32mIn[27], line 30\u001b[0m, in \u001b[0;36mpreprocess_vibration_dataframe\u001b[1;34m(df, target_length, cutoff)\u001b[0m\n\u001b[0;32m     24\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal_acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess_and_resample(\n\u001b[0;32m     25\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontal_acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m], fs\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], target_length\u001b[38;5;241m=\u001b[39mtarget_length, cutoff\u001b[38;5;241m=\u001b[39mcutoff\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxial_acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess_and_resample(\n\u001b[0;32m     28\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxial_acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m], fs\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], target_length\u001b[38;5;241m=\u001b[39mtarget_length, cutoff\u001b[38;5;241m=\u001b[39mcutoff\n\u001b[0;32m     29\u001b[0m )\n\u001b[1;32m---> 30\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical_acceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_resample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvertical_acceleration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msampling_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtachometer_signal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m preprocess_and_resample(\n\u001b[0;32m     34\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtachometer_signal\u001b[39m\u001b[38;5;124m'\u001b[39m], fs\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling_rate\u001b[39m\u001b[38;5;124m'\u001b[39m], target_length\u001b[38;5;241m=\u001b[39mtarget_length, cutoff\u001b[38;5;241m=\u001b[39mcutoff\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m processed_records\u001b[38;5;241m.\u001b[39mappend(record)\n",
      "Cell \u001b[1;32mIn[26], line 16\u001b[0m, in \u001b[0;36mpreprocess_and_resample\u001b[1;34m(signal, fs, target_length, cutoff, filter_order)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mFiltra e fa il resample di un segnale ad una lunghezza fissa.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m filtered \u001b[38;5;241m=\u001b[39m butter_lowpass_filter(signal, cutoff, fs, order\u001b[38;5;241m=\u001b[39mfilter_order)\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:3147\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(x, num, t, axis, window, domain)\u001b[0m\n\u001b[0;32m   3144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m domain \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   3145\u001b[0m     \u001b[38;5;66;03m# Forward transform\u001b[39;00m\n\u001b[0;32m   3146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m real_input:\n\u001b[1;32m-> 3147\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43msp_fft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Full complex FFT\u001b[39;00m\n\u001b[0;32m   3149\u001b[0m         X \u001b[38;5;241m=\u001b[39m sp_fft\u001b[38;5;241m.\u001b[39mfft(x, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\dswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\fft\\_backend.py:28\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[1;34m(method, args, kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\fft\\_basic_backend.py:72\u001b[0m, in \u001b[0;36mrfft\u001b[1;34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrfft\u001b[39m(x, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m          overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_1D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrfft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\fft\\_basic_backend.py:28\u001b[0m, in \u001b[0;36m_execute_1D\u001b[1;34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m     25\u001b[0m xp \u001b[38;5;241m=\u001b[39m array_namespace(x)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m norm \u001b[38;5;241m=\u001b[39m _validate_fft_args(workers, plan, norm)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\dswal\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\fft\\_pocketfft\\basic.py:61\u001b[0m, in \u001b[0;36mr2c\u001b[1;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp\u001b[38;5;241m.\u001b[39mshape[axis]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = preprocess_vibration_dataframe(df)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30cc73",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GearboxFaultDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Modello multi-input per la diagnosi di fault nei gearbox.\n",
    "    Gestisce segnali di vibrazione multi-assiali e condizioni operative variabili.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_length=61440, num_classes=11, confidence_output=True):\n",
    "        super(GearboxFaultDetector, self).__init__()\n",
    "        \n",
    "        self.input_length = input_length\n",
    "        self.num_classes = num_classes\n",
    "        self.confidence_output = confidence_output\n",
    "        \n",
    "        # Encoder CNN per ogni asse di vibrazione\n",
    "        self.horizontal_encoder = self._make_cnn_encoder()\n",
    "        self.axial_encoder = self._make_cnn_encoder()\n",
    "        self.vertical_encoder = self._make_cnn_encoder()\n",
    "        \n",
    "        # Encoder per il segnale tachometro\n",
    "        self.tacho_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=64, stride=8, padding=28),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(512)\n",
    "        )\n",
    "        \n",
    "        # Encoder per condizioni operative (rpm, torque)\n",
    "        self.operational_encoder = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion layer\n",
    "        fusion_input_dim = 512 * 3 + 512 + 128  # 3 assi + tacho + operational\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, 1024),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Output heads\n",
    "        self.health_classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "        if confidence_output:\n",
    "            self.confidence_head = nn.Sequential(\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()  # Output tra 0 e 1\n",
    "            )\n",
    "    \n",
    "    def _make_cnn_encoder(self):\n",
    "        \"\"\"Crea un encoder CNN per i segnali di vibrazione\"\"\"\n",
    "        return nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv1d(1, 64, kernel_size=64, stride=4, padding=30),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv1d(64, 128, kernel_size=32, stride=2, padding=15),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv1d(128, 256, kernel_size=16, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv1d(256, 512, kernel_size=8, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(512)\n",
    "        )\n",
    "    \n",
    "    def forward(self, horizontal, axial, vertical, tachometer, rpm, torque):\n",
    "        \"\"\"\n",
    "        Forward pass del modello\n",
    "        \n",
    "        Args:\n",
    "            horizontal, axial, vertical: tensori (batch_size, input_length)\n",
    "            tachometer: tensore (batch_size, input_length)\n",
    "            rpm, torque: tensori (batch_size, 1)\n",
    "        \"\"\"\n",
    "        batch_size = horizontal.size(0)\n",
    "        \n",
    "        # Reshape per CNN (add channel dimension)\n",
    "        horizontal = horizontal.unsqueeze(1)  # (batch_size, 1, input_length)\n",
    "        axial = axial.unsqueeze(1)\n",
    "        vertical = vertical.unsqueeze(1)\n",
    "        tachometer = tachometer.unsqueeze(1)\n",
    "        \n",
    "        # Encode vibration signals\n",
    "        h_feat = self.horizontal_encoder(horizontal)  # (batch_size, 512, 512)\n",
    "        a_feat = self.axial_encoder(axial)\n",
    "        v_feat = self.vertical_encoder(vertical)\n",
    "        \n",
    "        # Encode tachometer\n",
    "        t_feat = self.tacho_encoder(tachometer)\n",
    "        \n",
    "        # Flatten spatial dimensions\n",
    "        h_feat = h_feat.view(batch_size, -1)  # (batch_size, 512*512)\n",
    "        a_feat = a_feat.view(batch_size, -1)\n",
    "        v_feat = v_feat.view(batch_size, -1)\n",
    "        t_feat = t_feat.view(batch_size, -1)\n",
    "        \n",
    "        # Encode operational conditions\n",
    "        operational_conditions = torch.cat([rpm, torque], dim=1)  # (batch_size, 2)\n",
    "        op_feat = self.operational_encoder(operational_conditions)\n",
    "        \n",
    "        # Fusion\n",
    "        combined_features = torch.cat([h_feat, a_feat, v_feat, t_feat, op_feat], dim=1)\n",
    "        fused_features = self.fusion(combined_features)\n",
    "        \n",
    "        # Output predictions\n",
    "        health_logits = self.health_classifier(fused_features)\n",
    "        health_probs = F.softmax(health_logits, dim=1)\n",
    "        \n",
    "        if self.confidence_output:\n",
    "            confidence = self.confidence_head(fused_features)\n",
    "            return health_probs, confidence\n",
    "        else:\n",
    "            return health_probs\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Classe per preprocessare i dati del dataset gearbox\"\"\"\n",
    "    \n",
    "    def __init__(self, target_length=61440, overlap=0.5):\n",
    "        self.target_length = target_length\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def extract_segments(self, signal):\n",
    "        \"\"\"Estrae segmenti di lunghezza fissa da segnale variabile\"\"\"\n",
    "        if len(signal) < self.target_length:\n",
    "            # Padding per segnali troppo corti\n",
    "            padding = self.target_length - len(signal)\n",
    "            signal = np.pad(signal, (0, padding), mode='constant')\n",
    "            return [signal]\n",
    "        \n",
    "        segments = []\n",
    "        step = int(self.target_length * (1 - self.overlap))\n",
    "        \n",
    "        for i in range(0, len(signal) - self.target_length + 1, step):\n",
    "            segments.append(signal[i:i + self.target_length])\n",
    "        \n",
    "        return segments\n",
    "    \n",
    "    def normalize_signal(self, signal, method='standardize'):\n",
    "        \"\"\"Normalizza il segnale\"\"\"\n",
    "        if method == 'standardize':\n",
    "            return (signal - np.mean(signal)) / (np.std(signal) + 1e-8)\n",
    "        elif method == 'minmax':\n",
    "            min_val, max_val = np.min(signal), np.max(signal)\n",
    "            return (signal - min_val) / (max_val - min_val + 1e-8)\n",
    "        return signal\n",
    "    \n",
    "    def prepare_dataset(self, df):\n",
    "        \"\"\"Prepara il dataset per il training\"\"\"\n",
    "        X_horizontal, X_axial, X_vertical, X_tacho = [], [], [], []\n",
    "        X_rpm, X_torque = [], []\n",
    "        y_labels = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            # Estrai segmenti da ogni segnale\n",
    "            h_segments = self.extract_segments(row['horizontal_acceleration'])\n",
    "            a_segments = self.extract_segments(row['axial_acceleration'])\n",
    "            v_segments = self.extract_segments(row['vertical_acceleration'])\n",
    "            t_segments = self.extract_segments(row['tachometer_signal'])\n",
    "            \n",
    "            # Assicurati che tutti abbiano lo stesso numero di segmenti\n",
    "            min_segments = min(len(h_segments), len(a_segments), \n",
    "                             len(v_segments), len(t_segments))\n",
    "            \n",
    "            for i in range(min_segments):\n",
    "                X_horizontal.append(self.normalize_signal(h_segments[i]))\n",
    "                X_axial.append(self.normalize_signal(a_segments[i]))\n",
    "                X_vertical.append(self.normalize_signal(v_segments[i]))\n",
    "                X_tacho.append(self.normalize_signal(t_segments[i]))\n",
    "                \n",
    "                X_rpm.append(row['velocita'])\n",
    "                X_torque.append(row['torque'])\n",
    "                y_labels.append(row['health_level'])\n",
    "        \n",
    "        return {\n",
    "            'horizontal': np.array(X_horizontal),\n",
    "            'axial': np.array(X_axial),\n",
    "            'vertical': np.array(X_vertical),\n",
    "            'tachometer': np.array(X_tacho),\n",
    "            'rpm': np.array(X_rpm).reshape(-1, 1),\n",
    "            'torque': np.array(X_torque).reshape(-1, 1),\n",
    "            'labels': np.array(y_labels)\n",
    "        }\n",
    "\n",
    "# Esempio di utilizzo\n",
    "def train_model(df_train):\n",
    "    \"\"\"Esempio di training del modello\"\"\"\n",
    "    \n",
    "    # Preprocessa i dati\n",
    "    preprocessor = DataPreprocessor(target_length=61440, overlap=0.5)\n",
    "    data = preprocessor.prepare_dataset(df_train)\n",
    "    \n",
    "    # Inizializza il modello\n",
    "    model = GearboxFaultDetector(\n",
    "        input_length=61440, \n",
    "        num_classes=11, \n",
    "        confidence_output=True\n",
    "    )\n",
    "    \n",
    "    # Setup training\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_conf = nn.MSELoss()  # Per la confidenza\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    h_tensor = torch.FloatTensor(data['horizontal'])\n",
    "    a_tensor = torch.FloatTensor(data['axial'])\n",
    "    v_tensor = torch.FloatTensor(data['vertical'])\n",
    "    t_tensor = torch.FloatTensor(data['tachometer'])\n",
    "    rpm_tensor = torch.FloatTensor(data['rpm'])\n",
    "    torque_tensor = torch.FloatTensor(data['torque'])\n",
    "    labels_tensor = torch.LongTensor(data['labels'])\n",
    "    \n",
    "    print(f\"Dataset preparato: {len(data['labels'])} campioni\")\n",
    "    print(f\"Forme tensori - H:{h_tensor.shape}, A:{a_tensor.shape}, V:{v_tensor.shape}\")\n",
    "    \n",
    "    return model, (h_tensor, a_tensor, v_tensor, t_tensor, rpm_tensor, torque_tensor, labels_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
