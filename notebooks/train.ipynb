{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71ecec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts relative paths to absolute ones\n",
    "ROOT_TRAIN_DATA_FOLDER ='../data/raw/B - PHM America 2023 - Dataset/Data_Challenge_PHM2023_training_data'\n",
    "ROOT_VAL_DATA_FOLDER = '../data/raw/B - PHM America 2023 - Dataset/Data_Challenge_PHM2023_test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8758f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57cf438",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce10969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARICAMENTO DATASET ===\n",
      "Conteggio file in corso...\n",
      "Trovati 2016 file .txt da processare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing dataset:   0%|          | 0/2016 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing dataset: 100%|██████████| 2016/2016 [01:32<00:00, 21.76file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ordinamento dataset...\n",
      "Dataset caricato: 2016 file processati\n",
      "Health levels disponibili: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(6), np.int64(8)]\n",
      "Condizioni operative (rpm): [np.int64(100), np.int64(200), np.int64(300), np.int64(400), np.int64(500), np.int64(600), np.int64(700), np.int64(800), np.int64(900), np.int64(1000), np.int64(1200), np.int64(2100), np.int64(2700), np.int64(3000), np.int64(3600)]\n",
      "Condizioni operative (torque): [np.int64(50), np.int64(100), np.int64(200), np.int64(300), np.int64(400), np.int64(500)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "etichetta",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "health_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "velocita",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "torque",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "horizontal_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "axial_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "vertical_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tachometer_signal",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "sampling_rate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_samples",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "descrizione",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "52690980-4f56-4ed3-9c2a-a35cf0a11ffa",
       "rows": [
        [
         "0",
         "V100_50N_1.txt",
         "0",
         "0",
         "100",
         "50",
         "1",
         "[-0.46260182 -0.71244899 -0.55092912 ... -0.02406671 -0.05222724\n  0.04329526]",
         "[-0.49911102 -0.73771904 -0.56997536 ...  0.02012924 -0.00494402\n  0.07733866]",
         "[-0.42549879 -0.81448494 -0.54298996 ...  0.00084353 -0.03639214\n  0.11351455]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         null
        ],
        [
         "1",
         "V100_50N_2.txt",
         "0",
         "0",
         "100",
         "50",
         "2",
         "[ 0.08373726 -0.01240552 -0.05421212 ...  0.08386131 -0.11909299\n  0.08869946]",
         "[ 0.04308364 -0.0522654  -0.09993992 ...  0.0705112  -0.13254694\n  0.0815764 ]",
         "[ 0.09495697 -0.06374649 -0.13363867 ...  0.13954336 -0.19991574\n  0.13315666]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         null
        ],
        [
         "2",
         "V100_50N_3.txt",
         "0",
         "0",
         "100",
         "50",
         "3",
         "[-0.06376437  0.09676305 -0.04503204 ... -0.01873233  0.0525994\n -0.10085687]",
         "[-0.07804495  0.07745638 -0.0649786  ...  0.00659203  0.0839307\n -0.06886319]",
         "[-0.09857208  0.15340129 -0.08254508 ...  0.00361511  0.14231494\n -0.111948  ]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         null
        ],
        [
         "3",
         "V100_50N_4.txt",
         "0",
         "0",
         "100",
         "50",
         "4",
         "[ 0.07418501 -0.03634817 -0.08572214 ...  0.08783108 -0.06711386\n  0.09155273]",
         "[ 0.06933405 -0.03107672 -0.07251236 ...  0.06686204 -0.0981742\n  0.06709747]",
         "[ 0.15195525 -0.01518347 -0.08507566 ...  0.13086709 -0.14532754\n  0.15496784]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         null
        ],
        [
         "4",
         "V100_50N_5.txt",
         "0",
         "0",
         "100",
         "50",
         "5",
         "[-0.02816053  0.04416365  0.0573135  ... -0.11164968  0.10705963\n -0.09266923]",
         "[-0.06439003  0.02001153  0.03849276 ... -0.08887472  0.13172293\n -0.07733866]",
         "[-0.07965299  0.03108997  0.0639875  ... -0.19389056  0.16412613\n -0.15496784]",
         "[0. 0. 0. ... 0. 0. 0.]",
         "20480",
         "12.05",
         "246784",
         null
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>etichetta</th>\n",
       "      <th>health_level</th>\n",
       "      <th>velocita</th>\n",
       "      <th>torque</th>\n",
       "      <th>rep</th>\n",
       "      <th>horizontal_acceleration</th>\n",
       "      <th>axial_acceleration</th>\n",
       "      <th>vertical_acceleration</th>\n",
       "      <th>tachometer_signal</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>descrizione</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V100_50N_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4626018245, -0.7124489885, -0.5509291238, ...</td>\n",
       "      <td>[-0.4991110174, -0.7377190438, -0.5699753646, ...</td>\n",
       "      <td>[-0.4254987892, -0.814484938, -0.5429899587, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V100_50N_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.08373725705, -0.01240551956, -0.05421212049...</td>\n",
       "      <td>[0.04308363971, -0.05226539899, -0.09993991833...</td>\n",
       "      <td>[0.0949569657, -0.06374649093, -0.1336386738, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V100_50N_3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.06376437055, 0.09676305259, -0.04503203601...</td>\n",
       "      <td>[-0.07804495389, 0.07745637958, -0.06497860415...</td>\n",
       "      <td>[-0.0985720786, 0.153401291, -0.08254507805, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V100_50N_4.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.07418500699, -0.03634817232, -0.08572214018...</td>\n",
       "      <td>[0.06933405406, -0.03107672372, -0.07251235535...</td>\n",
       "      <td>[0.1519552459, -0.01518347421, -0.08507565708,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V100_50N_5.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.02816052941, 0.04416364964, 0.05731350038,...</td>\n",
       "      <td>[-0.06439002983, 0.02001152664, 0.03849276007,...</td>\n",
       "      <td>[-0.07965298772, 0.031089971, 0.06398749846, -...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20480</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name etichetta  health_level  velocita  torque  rep  \\\n",
       "0  V100_50N_1.txt         0             0       100      50    1   \n",
       "1  V100_50N_2.txt         0             0       100      50    2   \n",
       "2  V100_50N_3.txt         0             0       100      50    3   \n",
       "3  V100_50N_4.txt         0             0       100      50    4   \n",
       "4  V100_50N_5.txt         0             0       100      50    5   \n",
       "\n",
       "                             horizontal_acceleration  \\\n",
       "0  [-0.4626018245, -0.7124489885, -0.5509291238, ...   \n",
       "1  [0.08373725705, -0.01240551956, -0.05421212049...   \n",
       "2  [-0.06376437055, 0.09676305259, -0.04503203601...   \n",
       "3  [0.07418500699, -0.03634817232, -0.08572214018...   \n",
       "4  [-0.02816052941, 0.04416364964, 0.05731350038,...   \n",
       "\n",
       "                                  axial_acceleration  \\\n",
       "0  [-0.4991110174, -0.7377190438, -0.5699753646, ...   \n",
       "1  [0.04308363971, -0.05226539899, -0.09993991833...   \n",
       "2  [-0.07804495389, 0.07745637958, -0.06497860415...   \n",
       "3  [0.06933405406, -0.03107672372, -0.07251235535...   \n",
       "4  [-0.06439002983, 0.02001152664, 0.03849276007,...   \n",
       "\n",
       "                               vertical_acceleration  \\\n",
       "0  [-0.4254987892, -0.814484938, -0.5429899587, -...   \n",
       "1  [0.0949569657, -0.06374649093, -0.1336386738, ...   \n",
       "2  [-0.0985720786, 0.153401291, -0.08254507805, -...   \n",
       "3  [0.1519552459, -0.01518347421, -0.08507565708,...   \n",
       "4  [-0.07965298772, 0.031089971, 0.06398749846, -...   \n",
       "\n",
       "                                   tachometer_signal  sampling_rate  duration  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          20480     12.05   \n",
       "\n",
       "   num_samples descrizione  \n",
       "0       246784        None  \n",
       "1       246784        None  \n",
       "2       246784        None  \n",
       "3       246784        None  \n",
       "4       246784        None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as stats\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "def parse_vibration_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Parsa il dataset di vibrazione e crea un DataFrame pandas con una riga per ogni file.\n",
    "    Ogni riga contiene gli array completi delle serie temporali di vibrazione.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Percorso alla cartella principale del dataset\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con colonne etichetta, velocità, torque, rep e array di dati di vibrazione (una riga per file)\n",
    "    \"\"\"\n",
    "\n",
    "    data_list = []\n",
    "    \n",
    "    # Prima passata: conta il numero totale di file .txt\n",
    "    print(\"Conteggio file in corso...\")\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        total_files += sum(1 for file in files if file.endswith('.txt'))\n",
    "    \n",
    "    print(f\"Trovati {total_files} file .txt da processare\")\n",
    "\n",
    "    # Seconda passada: processa i file con progress bar\n",
    "    with tqdm(total=total_files, desc=\"Parsing dataset\", unit=\"file\") as pbar:\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    folder_name = os.path.basename(root)\n",
    "                    if 'Pitting_degradation_level_' in folder_name:\n",
    "                        etichetta_full = folder_name.replace('Pitting_degradation_level_', '')\n",
    "                        if '(' in etichetta_full:\n",
    "                            etichetta = etichetta_full.split('(')[0].strip()\n",
    "                            descrizione = etichetta_full.split('(')[1].replace(')', '').strip()\n",
    "                        else:\n",
    "                            etichetta = etichetta_full.strip()\n",
    "                            descrizione = None\n",
    "                    else:\n",
    "                        etichetta = folder_name\n",
    "                        descrizione = None\n",
    "\n",
    "                    # ERRORE CORRETTO: regex pattern per V100_200N_2.txt\n",
    "                    pattern = r'V(\\d+)_(\\d+)N_(\\d+)\\.txt'\n",
    "                    match = re.search(pattern, file)\n",
    "\n",
    "                    if match:\n",
    "                        velocita = int(match.group(1))\n",
    "                        torque = int(match.group(2))\n",
    "                        rep = int(match.group(3))\n",
    "\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        try:\n",
    "                            # Carica tutti i dati del file una volta sola\n",
    "                            data = np.loadtxt(file_path)\n",
    "                            \n",
    "                            # Calcola informazioni aggiuntive sui dati\n",
    "                            sampling_rate = 20480  # Hz come specificato nella documentazione\n",
    "                            duration = len(data) / sampling_rate\n",
    "                            \n",
    "                            # Crea un record per l'intero file\n",
    "                            record = {\n",
    "                                'file_name': file,\n",
    "                                'etichetta': etichetta,\n",
    "                                'health_level': int(etichetta) if etichetta.isdigit() else etichetta,\n",
    "                                'velocita': velocita,\n",
    "                                'torque': torque,\n",
    "                                'rep': rep,\n",
    "                                'horizontal_acceleration': data[:, 0],  # Array completo\n",
    "                                'axial_acceleration': data[:, 1],       # Array completo\n",
    "                                'vertical_acceleration': data[:, 2],    # Array completo\n",
    "                                'tachometer_signal': data[:, 3],        # Array completo\n",
    "                                'sampling_rate': sampling_rate,\n",
    "                                'duration': duration,\n",
    "                                'num_samples': len(data),\n",
    "                                'descrizione': descrizione\n",
    "                            }\n",
    "                            # ERRORE CORRETTO: aggiungi record invece di data\n",
    "                            data_list.append(record)\n",
    "\n",
    "                        except Exception as e:\n",
    "                            tqdm.write(f\"Errore nel leggere il file {file_path}: {e}\")\n",
    "                            continue\n",
    "                    else:\n",
    "                        tqdm.write(f\"Nome file non riconosciuto: {file}\")\n",
    "                    \n",
    "                    # Aggiorna la progress bar\n",
    "                    pbar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "\n",
    "    if not df.empty:\n",
    "        print(\"\\nOrdinamento dataset...\")\n",
    "        df = df.sort_values(['health_level', 'velocita', 'torque', 'rep']).reset_index(drop=True)\n",
    "        print(f\"Dataset caricato: {len(df)} file processati\")\n",
    "        print(f\"Health levels disponibili: {sorted(df['health_level'].unique())}\")\n",
    "        print(f\"Condizioni operative (rpm): {sorted(df['velocita'].unique())}\")\n",
    "        print(f\"Condizioni operative (torque): {sorted(df['torque'].unique())}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_signal_features(df, signal_column):\n",
    "    \"\"\"\n",
    "    Estrae features statistiche e nel dominio della frequenza da una colonna di segnali.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con i dati\n",
    "        signal_column (str): Nome della colonna contenente gli array dei segnali\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con features estratte\n",
    "    \"\"\"\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    # Progress bar per l'estrazione delle features\n",
    "    with tqdm(total=len(df), desc=f\"Estraendo features da {signal_column}\", unit=\"segnale\") as pbar:\n",
    "        for idx, row in df.iterrows():\n",
    "            signal = row[signal_column]\n",
    "            \n",
    "            # Features statistiche nel dominio del tempo\n",
    "            features = {\n",
    "                f'{signal_column}_mean': np.mean(signal),\n",
    "                f'{signal_column}_std': np.std(signal),\n",
    "                f'{signal_column}_rms': np.sqrt(np.mean(signal**2)),\n",
    "                f'{signal_column}_peak': np.max(np.abs(signal)),\n",
    "                f'{signal_column}_peak_to_peak': np.ptp(signal),\n",
    "                f'{signal_column}_skewness': stats.skew(signal),\n",
    "                f'{signal_column}_kurtosis': stats.kurtosis(signal),\n",
    "                f'{signal_column}_crest_factor': np.max(np.abs(signal)) / np.sqrt(np.mean(signal**2)),\n",
    "            }\n",
    "            \n",
    "            # Features nel dominio della frequenza\n",
    "            sampling_rate = row['sampling_rate']\n",
    "            fft_vals = np.abs(fft(signal))\n",
    "            freqs = fftfreq(len(signal), 1/sampling_rate)\n",
    "            \n",
    "            # Considera solo le frequenze positive\n",
    "            positive_freq_idx = freqs > 0\n",
    "            fft_positive = fft_vals[positive_freq_idx]\n",
    "            freqs_positive = freqs[positive_freq_idx]\n",
    "            \n",
    "            # Trova la frequenza dominante\n",
    "            dominant_freq_idx = np.argmax(fft_positive)\n",
    "            features[f'{signal_column}_dominant_freq'] = freqs_positive[dominant_freq_idx]\n",
    "            features[f'{signal_column}_dominant_magnitude'] = fft_positive[dominant_freq_idx]\n",
    "            \n",
    "            # Features spettrali\n",
    "            total_power = np.sum(fft_positive**2)\n",
    "            features[f'{signal_column}_spectral_centroid'] = np.sum(freqs_positive * fft_positive**2) / total_power\n",
    "            features[f'{signal_column}_spectral_rolloff'] = freqs_positive[np.where(np.cumsum(fft_positive**2) >= 0.85 * total_power)[0][0]]\n",
    "            \n",
    "            features_list.append(features)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "def extract_all_features(df):\n",
    "    \"\"\"\n",
    "    Estrae tutte le features da tutti i segnali di accelerazione con progress bar complessiva.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con i dati grezzi\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame completo con tutte le features\n",
    "    \"\"\"\n",
    "    print(\"Iniziando estrazione features da tutti i segnali...\")\n",
    "    \n",
    "    # Estrai features da tutti i segnali di accelerazione\n",
    "    horizontal_features = extract_signal_features(df, 'horizontal_acceleration')\n",
    "    axial_features = extract_signal_features(df, 'axial_acceleration')\n",
    "    vertical_features = extract_signal_features(df, 'vertical_acceleration')\n",
    "\n",
    "    print(\"Combinando tutte le features...\")\n",
    "    # Combina tutte le features\n",
    "    features_df = pd.concat([\n",
    "        df[['file_name', 'health_level', 'velocita', 'torque', 'rep']],\n",
    "        horizontal_features,\n",
    "        axial_features, \n",
    "        vertical_features\n",
    "    ], axis=1)\n",
    "\n",
    "    print(f\"Features dataset completato! Shape: {features_df.shape}\")\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# Esempio di utilizzo:\n",
    "# Carica il dataset\n",
    "print(\"=== CARICAMENTO DATASET ===\")\n",
    "df = parse_vibration_dataset(ROOT_TRAIN_DATA_FOLDER)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "895075ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/processed/train_data_walt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967773ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ESTRAZIONE FEATURES ===\n",
      "Iniziando estrazione features da tutti i segnali...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estraendo features da horizontal_acceleration: 100%|██████████| 2016/2016 [01:04<00:00, 31.24segnale/s]\n",
      "Estraendo features da axial_acceleration: 100%|██████████| 2016/2016 [01:04<00:00, 31.06segnale/s]\n",
      "Estraendo features da vertical_acceleration: 100%|██████████| 2016/2016 [01:01<00:00, 32.53segnale/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinando tutte le features...\n",
      "Features dataset completato! Shape: (2016, 41)\n",
      "\n",
      "=== COMPLETATO ===\n",
      "Dataset finale: 2016 campioni, 41 features\n",
      "Colonne delle features: ['horizontal_acceleration_mean', 'horizontal_acceleration_std', 'horizontal_acceleration_rms', 'horizontal_acceleration_peak', 'horizontal_acceleration_peak_to_peak', 'horizontal_acceleration_skewness', 'horizontal_acceleration_kurtosis', 'horizontal_acceleration_crest_factor', 'horizontal_acceleration_dominant_freq', 'horizontal_acceleration_dominant_magnitude', 'horizontal_acceleration_spectral_centroid', 'horizontal_acceleration_spectral_rolloff', 'axial_acceleration_mean', 'axial_acceleration_std', 'axial_acceleration_rms', 'axial_acceleration_peak', 'axial_acceleration_peak_to_peak', 'axial_acceleration_skewness', 'axial_acceleration_kurtosis', 'axial_acceleration_crest_factor', 'axial_acceleration_dominant_freq', 'axial_acceleration_dominant_magnitude', 'axial_acceleration_spectral_centroid', 'axial_acceleration_spectral_rolloff', 'vertical_acceleration_mean', 'vertical_acceleration_std', 'vertical_acceleration_rms', 'vertical_acceleration_peak', 'vertical_acceleration_peak_to_peak', 'vertical_acceleration_skewness', 'vertical_acceleration_kurtosis', 'vertical_acceleration_crest_factor', 'vertical_acceleration_dominant_freq', 'vertical_acceleration_dominant_magnitude', 'vertical_acceleration_spectral_centroid', 'vertical_acceleration_spectral_rolloff']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== ESTRAZIONE FEATURES ===\")\n",
    "# Estrai tutte le features\n",
    "features_df = extract_all_features(df)\n",
    "\n",
    "print(f\"\\n=== COMPLETATO ===\")\n",
    "print(f\"Dataset finale: {features_df.shape[0]} campioni, {features_df.shape[1]} features\")\n",
    "print(f\"Colonne delle features: {[col for col in features_df.columns if col not in ['file_name', 'health_level', 'velocita', 'torque', 'rep']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366156de",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6122223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt, resample\n",
    "import numpy as np\n",
    "\n",
    "def butter_lowpass_filter(signal, cutoff, fs, order=5):\n",
    "    \"\"\"Applica un filtro passa basso Butterworth.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def preprocess_and_resample(signal, fs=20480, target_length=61440, cutoff=5000, filter_order=5):\n",
    "    \"\"\"\n",
    "    Filtra e fa il resample di un segnale ad una lunghezza fissa.\n",
    "    \"\"\"\n",
    "    if len(signal) == target_length:\n",
    "        return signal\n",
    "    filtered = butter_lowpass_filter(signal, cutoff, fs, order=filter_order)\n",
    "    return resample(filtered, target_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb39fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vibration_dataframe(df, target_length=61440, cutoff=5000):\n",
    "    \"\"\"\n",
    "    Applica filtraggio e resample a tutti i segnali accelerometrici e tachimetro nel DataFrame.\n",
    "    Ritorna un nuovo DataFrame con colonne preprocessate.\n",
    "    \"\"\"\n",
    "    processed_records = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocessing\"):\n",
    "        try:\n",
    "            record = {\n",
    "                'file_name': row['file_name'],\n",
    "                'etichetta': row['etichetta'],\n",
    "                'health_level': row['health_level'],\n",
    "                'velocita': row['velocita'],\n",
    "                'torque': row['torque'],\n",
    "                'rep': row['rep'],\n",
    "                'sampling_rate': row['sampling_rate'],\n",
    "                'descrizione': row['descrizione'],\n",
    "                'duration': row['duration'],\n",
    "                'num_samples': row['num_samples']\n",
    "            }\n",
    "\n",
    "            # Applica filtro + resample ai 4 segnali\n",
    "            record['horizontal_acceleration'] = preprocess_and_resample(\n",
    "                row['horizontal_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['axial_acceleration'] = preprocess_and_resample(\n",
    "                row['axial_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['vertical_acceleration'] = preprocess_and_resample(\n",
    "                row['vertical_acceleration'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "            record['tachometer_signal'] = preprocess_and_resample(\n",
    "                row['tachometer_signal'], fs=row['sampling_rate'], target_length=target_length, cutoff=cutoff\n",
    "            )\n",
    "\n",
    "            processed_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Errore durante il preprocessing del file {row['file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(processed_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41af7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   0%|          | 0/2016 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 2016/2016 [01:03<00:00, 31.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "file_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "etichetta",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "health_level",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "velocita",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "torque",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rep",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sampling_rate",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "descrizione",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "duration",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "num_samples",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "horizontal_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "axial_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "vertical_acceleration",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "tachometer_signal",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "70ea8b44-300d-41b9-89c7-10f2eb548b10",
       "rows": [
        [
         "0",
         "V100_50N_1.txt",
         "0",
         "0",
         "100",
         "50",
         "1",
         "20480",
         null,
         "12.05",
         "246784",
         "[-0.33906518 -0.63984773 -0.55614155 ...  0.02330766 -0.04043992\n  0.03268511]",
         "[-0.33771634 -0.68680063 -0.62513521 ...  0.02908055 -0.03100478\n  0.07229409]",
         "[-0.31877221 -0.67499386 -0.56996399 ...  0.05564791 -0.04022665\n  0.05374091]",
         "[ 5.65917937e-05 -5.65986510e-05  5.66055156e-05 ... -5.65712655e-05\n  5.65781010e-05 -5.65849437e-05]"
        ],
        [
         "1",
         "V100_50N_2.txt",
         "0",
         "0",
         "100",
         "50",
         "2",
         "20480",
         null,
         "12.05",
         "246784",
         "[ 0.03545689  0.01372752  0.00922664 ... -0.0197649  -0.03661549\n -0.0046206 ]",
         "[ 0.00577763 -0.01978204  0.0213115  ... -0.01273848  0.00777557\n -0.01157211]",
         "[ 0.02635219 -0.00607074  0.02084627 ... -0.02355738 -0.03691726\n -0.00159763]",
         "[ 7.51330173e-06 -7.49650567e-06  7.47971720e-06 ... -7.56373558e-06\n  7.54691666e-06 -7.53010539e-06]"
        ],
        [
         "2",
         "V100_50N_3.txt",
         "0",
         "0",
         "100",
         "50",
         "3",
         "20480",
         null,
         "12.05",
         "246784",
         "[-0.03631877 -0.00537023 -0.01110156 ... -0.00258422  0.02116038\n -0.01105689]",
         "[-0.03717833 -0.0118958  -0.01173577 ...  0.00715077 -0.01106443\n  0.01630043]",
         "[-0.04122466 -0.0062524  -0.02313433 ...  0.00327744  0.0238082\n  0.022577  ]",
         "[ 4.91494077e-06 -4.90148366e-06  4.88805258e-06 ... -4.95546877e-06\n  4.94193327e-06 -4.92842395e-06]"
        ],
        [
         "3",
         "V100_50N_4.txt",
         "0",
         "0",
         "100",
         "50",
         "4",
         "20480",
         null,
         "12.05",
         "246784",
         "[ 0.02856591 -0.01806498  0.010932   ... -0.00240999 -0.01534011\n  0.01059201]",
         "[ 0.01823003 -0.0075622  -0.00968801 ...  0.00843434  0.00890843\n -0.00200516]",
         "[ 0.07111735  0.00405924  0.00309437 ...  0.0068595  -0.0209396\n -0.00586547]",
         "[ 1.97935712e-05 -1.97754294e-05  1.97573120e-05 ... -1.98481430e-05\n  1.98299279e-05 -1.98117373e-05]"
        ],
        [
         "4",
         "V100_50N_5.txt",
         "0",
         "0",
         "100",
         "50",
         "5",
         "20480",
         null,
         "12.05",
         "246784",
         "[-0.02285861 -0.00499745 -0.02170822 ...  0.00823133  0.01881788\n -0.0146191 ]",
         "[-0.03536673 -0.01678817 -0.0244586  ... -0.0015663   0.00220731\n  0.01000086]",
         "[-0.06646321 -0.01544385 -0.01268078 ... -0.00275567  0.0064918\n -0.02547542]",
         "[-5.07980529e-05  5.07741269e-05 -5.07502191e-05 ...  5.08699403e-05\n -5.08459596e-05  5.08219971e-05]"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>etichetta</th>\n",
       "      <th>health_level</th>\n",
       "      <th>velocita</th>\n",
       "      <th>torque</th>\n",
       "      <th>rep</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>descrizione</th>\n",
       "      <th>duration</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>horizontal_acceleration</th>\n",
       "      <th>axial_acceleration</th>\n",
       "      <th>vertical_acceleration</th>\n",
       "      <th>tachometer_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V100_50N_1.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>20480</td>\n",
       "      <td>None</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>[-0.3390651848864094, -0.6398477262116601, -0....</td>\n",
       "      <td>[-0.3377163350050821, -0.6868006344518762, -0....</td>\n",
       "      <td>[-0.3187722144162405, -0.6749938554517663, -0....</td>\n",
       "      <td>[5.6591793740345864e-05, -5.6598651031449266e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V100_50N_2.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>20480</td>\n",
       "      <td>None</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>[0.03545688931249989, 0.013727522098811703, 0....</td>\n",
       "      <td>[0.005777631851004292, -0.01978203838148209, 0...</td>\n",
       "      <td>[0.0263521858293282, -0.006070741684336028, 0....</td>\n",
       "      <td>[7.513301726687674e-06, -7.496505671335418e-06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V100_50N_3.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>20480</td>\n",
       "      <td>None</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>[-0.036318766502895596, -0.005370231054060265,...</td>\n",
       "      <td>[-0.037178328805188364, -0.011895801141760537,...</td>\n",
       "      <td>[-0.041224658764366956, -0.006252398846337842,...</td>\n",
       "      <td>[4.914940765850561e-06, -4.901483662849729e-06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V100_50N_4.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>20480</td>\n",
       "      <td>None</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>[0.028565906165762944, -0.01806498462841457, 0...</td>\n",
       "      <td>[0.018230028717382312, -0.007562195813883986, ...</td>\n",
       "      <td>[0.07111734708162708, 0.0040592406639602995, 0...</td>\n",
       "      <td>[1.9793571189669363e-05, -1.9775429420732442e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V100_50N_5.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>20480</td>\n",
       "      <td>None</td>\n",
       "      <td>12.05</td>\n",
       "      <td>246784</td>\n",
       "      <td>[-0.02285860755254898, -0.004997454693991424, ...</td>\n",
       "      <td>[-0.03536672838920975, -0.01678817108586196, -...</td>\n",
       "      <td>[-0.06646321348959842, -0.015443852421977173, ...</td>\n",
       "      <td>[-5.079805290671204e-05, 5.077412692778585e-05...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name etichetta  health_level  velocita  torque  rep  \\\n",
       "0  V100_50N_1.txt         0             0       100      50    1   \n",
       "1  V100_50N_2.txt         0             0       100      50    2   \n",
       "2  V100_50N_3.txt         0             0       100      50    3   \n",
       "3  V100_50N_4.txt         0             0       100      50    4   \n",
       "4  V100_50N_5.txt         0             0       100      50    5   \n",
       "\n",
       "   sampling_rate descrizione  duration  num_samples  \\\n",
       "0          20480        None     12.05       246784   \n",
       "1          20480        None     12.05       246784   \n",
       "2          20480        None     12.05       246784   \n",
       "3          20480        None     12.05       246784   \n",
       "4          20480        None     12.05       246784   \n",
       "\n",
       "                             horizontal_acceleration  \\\n",
       "0  [-0.3390651848864094, -0.6398477262116601, -0....   \n",
       "1  [0.03545688931249989, 0.013727522098811703, 0....   \n",
       "2  [-0.036318766502895596, -0.005370231054060265,...   \n",
       "3  [0.028565906165762944, -0.01806498462841457, 0...   \n",
       "4  [-0.02285860755254898, -0.004997454693991424, ...   \n",
       "\n",
       "                                  axial_acceleration  \\\n",
       "0  [-0.3377163350050821, -0.6868006344518762, -0....   \n",
       "1  [0.005777631851004292, -0.01978203838148209, 0...   \n",
       "2  [-0.037178328805188364, -0.011895801141760537,...   \n",
       "3  [0.018230028717382312, -0.007562195813883986, ...   \n",
       "4  [-0.03536672838920975, -0.01678817108586196, -...   \n",
       "\n",
       "                               vertical_acceleration  \\\n",
       "0  [-0.3187722144162405, -0.6749938554517663, -0....   \n",
       "1  [0.0263521858293282, -0.006070741684336028, 0....   \n",
       "2  [-0.041224658764366956, -0.006252398846337842,...   \n",
       "3  [0.07111734708162708, 0.0040592406639602995, 0...   \n",
       "4  [-0.06646321348959842, -0.015443852421977173, ...   \n",
       "\n",
       "                                   tachometer_signal  \n",
       "0  [5.6591793740345864e-05, -5.6598651031449266e-...  \n",
       "1  [7.513301726687674e-06, -7.496505671335418e-06...  \n",
       "2  [4.914940765850561e-06, -4.901483662849729e-06...  \n",
       "3  [1.9793571189669363e-05, -1.9775429420732442e-...  \n",
       "4  [-5.079805290671204e-05, 5.077412692778585e-05...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = preprocess_vibration_dataframe(df)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de30cc73",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e09a3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GearboxFaultDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Modello multi-input per la diagnosi di fault nei gearbox.\n",
    "    Gestisce segnali di vibrazione multi-assiali e condizioni operative variabili.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_length=61440, num_classes=11, confidence_output=True):\n",
    "        super(GearboxFaultDetector, self).__init__()\n",
    "        \n",
    "        self.input_length = input_length\n",
    "        self.num_classes = num_classes\n",
    "        self.confidence_output = confidence_output\n",
    "        \n",
    "        # Encoder CNN per ogni asse di vibrazione\n",
    "        self.horizontal_encoder = self._make_cnn_encoder()\n",
    "        self.axial_encoder = self._make_cnn_encoder()\n",
    "        self.vertical_encoder = self._make_cnn_encoder()\n",
    "        \n",
    "        # Encoder per il segnale tachometro\n",
    "        self.tacho_encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=64, stride=8, padding=28),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(512)\n",
    "        )\n",
    "        \n",
    "        # Encoder per condizioni operative (rpm, torque)\n",
    "        self.operational_encoder = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Fusion layer\n",
    "        fusion_input_dim = 512 * 3 + 512 + 128  # 3 assi + tacho + operational\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, 1024),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Output heads\n",
    "        self.health_classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "        if confidence_output:\n",
    "            self.confidence_head = nn.Sequential(\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 1),\n",
    "                nn.Sigmoid()  # Output tra 0 e 1\n",
    "            )\n",
    "    \n",
    "    def _make_cnn_encoder(self):\n",
    "        \"\"\"Crea un encoder CNN per i segnali di vibrazione\"\"\"\n",
    "        return nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv1d(1, 64, kernel_size=64, stride=4, padding=30),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv1d(64, 128, kernel_size=32, stride=2, padding=15),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv1d(128, 256, kernel_size=16, stride=2, padding=7),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv1d(256, 512, kernel_size=8, stride=2, padding=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(512)\n",
    "        )\n",
    "    \n",
    "    def forward(self, horizontal, axial, vertical, tachometer, rpm, torque):\n",
    "        \"\"\"\n",
    "        Forward pass del modello\n",
    "        \n",
    "        Args:\n",
    "            horizontal, axial, vertical: tensori (batch_size, input_length)\n",
    "            tachometer: tensore (batch_size, input_length)\n",
    "            rpm, torque: tensori (batch_size, 1)\n",
    "        \"\"\"\n",
    "        batch_size = horizontal.size(0)\n",
    "        \n",
    "        # Reshape per CNN (add channel dimension)\n",
    "        horizontal = horizontal.unsqueeze(1)  # (batch_size, 1, input_length)\n",
    "        axial = axial.unsqueeze(1)\n",
    "        vertical = vertical.unsqueeze(1)\n",
    "        tachometer = tachometer.unsqueeze(1)\n",
    "        \n",
    "        # Encode vibration signals\n",
    "        h_feat = self.horizontal_encoder(horizontal)  # (batch_size, 512, 512)\n",
    "        a_feat = self.axial_encoder(axial)\n",
    "        v_feat = self.vertical_encoder(vertical)\n",
    "        \n",
    "        # Encode tachometer\n",
    "        t_feat = self.tacho_encoder(tachometer)\n",
    "        \n",
    "        # Flatten spatial dimensions\n",
    "        h_feat = h_feat.view(batch_size, -1)  # (batch_size, 512*512)\n",
    "        a_feat = a_feat.view(batch_size, -1)\n",
    "        v_feat = v_feat.view(batch_size, -1)\n",
    "        t_feat = t_feat.view(batch_size, -1)\n",
    "        \n",
    "        # Encode operational conditions\n",
    "        operational_conditions = torch.cat([rpm, torque], dim=1)  # (batch_size, 2)\n",
    "        op_feat = self.operational_encoder(operational_conditions)\n",
    "        \n",
    "        # Fusion\n",
    "        combined_features = torch.cat([h_feat, a_feat, v_feat, t_feat, op_feat], dim=1)\n",
    "        fused_features = self.fusion(combined_features)\n",
    "        \n",
    "        # Output predictions\n",
    "        health_logits = self.health_classifier(fused_features)\n",
    "        health_probs = F.softmax(health_logits, dim=1)\n",
    "        \n",
    "        if self.confidence_output:\n",
    "            confidence = self.confidence_head(fused_features)\n",
    "            return health_probs, confidence\n",
    "        else:\n",
    "            return health_probs\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Classe per preprocessare i dati del dataset gearbox\"\"\"\n",
    "    \n",
    "    def __init__(self, target_length=61440, overlap=0.5):\n",
    "        self.target_length = target_length\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def extract_segments(self, signal):\n",
    "        \"\"\"Estrae segmenti di lunghezza fissa da segnale variabile\"\"\"\n",
    "        if len(signal) < self.target_length:\n",
    "            # Padding per segnali troppo corti\n",
    "            padding = self.target_length - len(signal)\n",
    "            signal = np.pad(signal, (0, padding), mode='constant')\n",
    "            return [signal]\n",
    "        \n",
    "        segments = []\n",
    "        step = int(self.target_length * (1 - self.overlap))\n",
    "        \n",
    "        for i in range(0, len(signal) - self.target_length + 1, step):\n",
    "            segments.append(signal[i:i + self.target_length])\n",
    "        \n",
    "        return segments\n",
    "    \n",
    "    def normalize_signal(self, signal, method='standardize'):\n",
    "        \"\"\"Normalizza il segnale\"\"\"\n",
    "        if method == 'standardize':\n",
    "            return (signal - np.mean(signal)) / (np.std(signal) + 1e-8)\n",
    "        elif method == 'minmax':\n",
    "            min_val, max_val = np.min(signal), np.max(signal)\n",
    "            return (signal - min_val) / (max_val - min_val + 1e-8)\n",
    "        return signal\n",
    "    \n",
    "    def prepare_dataset(self, df):\n",
    "        \"\"\"Prepara il dataset per il training\"\"\"\n",
    "        X_horizontal, X_axial, X_vertical, X_tacho = [], [], [], []\n",
    "        X_rpm, X_torque = [], []\n",
    "        y_labels = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            # Estrai segmenti da ogni segnale\n",
    "            h_segments = self.extract_segments(row['horizontal_acceleration'])\n",
    "            a_segments = self.extract_segments(row['axial_acceleration'])\n",
    "            v_segments = self.extract_segments(row['vertical_acceleration'])\n",
    "            t_segments = self.extract_segments(row['tachometer_signal'])\n",
    "            \n",
    "            # Assicurati che tutti abbiano lo stesso numero di segmenti\n",
    "            min_segments = min(len(h_segments), len(a_segments), \n",
    "                             len(v_segments), len(t_segments))\n",
    "            \n",
    "            for i in range(min_segments):\n",
    "                X_horizontal.append(self.normalize_signal(h_segments[i]))\n",
    "                X_axial.append(self.normalize_signal(a_segments[i]))\n",
    "                X_vertical.append(self.normalize_signal(v_segments[i]))\n",
    "                X_tacho.append(self.normalize_signal(t_segments[i]))\n",
    "                \n",
    "                X_rpm.append(row['velocita'])\n",
    "                X_torque.append(row['torque'])\n",
    "                y_labels.append(row['health_level'])\n",
    "        \n",
    "        return {\n",
    "            'horizontal': np.array(X_horizontal),\n",
    "            'axial': np.array(X_axial),\n",
    "            'vertical': np.array(X_vertical),\n",
    "            'tachometer': np.array(X_tacho),\n",
    "            'rpm': np.array(X_rpm).reshape(-1, 1),\n",
    "            'torque': np.array(X_torque).reshape(-1, 1),\n",
    "            'labels': np.array(y_labels)\n",
    "        }\n",
    "\n",
    "# Esempio di utilizzo\n",
    "def train_model(df_train):\n",
    "    \"\"\"Esempio di training del modello\"\"\"\n",
    "    \n",
    "    # Preprocessa i dati\n",
    "    preprocessor = DataPreprocessor(target_length=61440, overlap=0.5)\n",
    "    data = preprocessor.prepare_dataset(df_train)\n",
    "    \n",
    "    # Inizializza il modello\n",
    "    model = GearboxFaultDetector(\n",
    "        input_length=61440, \n",
    "        num_classes=11, \n",
    "        confidence_output=True\n",
    "    )\n",
    "    \n",
    "    # Setup training\n",
    "    criterion_class = nn.CrossEntropyLoss()\n",
    "    criterion_conf = nn.MSELoss()  # Per la confidenza\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    h_tensor = torch.FloatTensor(data['horizontal'])\n",
    "    a_tensor = torch.FloatTensor(data['axial'])\n",
    "    v_tensor = torch.FloatTensor(data['vertical'])\n",
    "    t_tensor = torch.FloatTensor(data['tachometer'])\n",
    "    rpm_tensor = torch.FloatTensor(data['rpm'])\n",
    "    torque_tensor = torch.FloatTensor(data['torque'])\n",
    "    labels_tensor = torch.LongTensor(data['labels'])\n",
    "    \n",
    "    print(f\"Dataset preparato: {len(data['labels'])} campioni\")\n",
    "    print(f\"Forme tensori - H:{h_tensor.shape}, A:{a_tensor.shape}, V:{v_tensor.shape}\")\n",
    "    \n",
    "    return model, (h_tensor, a_tensor, v_tensor, t_tensor, rpm_tensor, torque_tensor, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57d5f197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparato: 2016 campioni\n",
      "Forme tensori - H:torch.Size([2016, 61440]), A:torch.Size([2016, 61440]), V:torch.Size([2016, 61440])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(GearboxFaultDetector(\n",
       "   (horizontal_encoder): Sequential(\n",
       "     (0): Conv1d(1, 64, kernel_size=(64,), stride=(4,), padding=(30,))\n",
       "     (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (4): Conv1d(64, 128, kernel_size=(32,), stride=(2,), padding=(15,))\n",
       "     (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (6): ReLU()\n",
       "     (7): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (8): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
       "     (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (10): ReLU()\n",
       "     (11): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (12): Conv1d(256, 512, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "     (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (14): ReLU()\n",
       "     (15): AdaptiveAvgPool1d(output_size=512)\n",
       "   )\n",
       "   (axial_encoder): Sequential(\n",
       "     (0): Conv1d(1, 64, kernel_size=(64,), stride=(4,), padding=(30,))\n",
       "     (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (4): Conv1d(64, 128, kernel_size=(32,), stride=(2,), padding=(15,))\n",
       "     (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (6): ReLU()\n",
       "     (7): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (8): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
       "     (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (10): ReLU()\n",
       "     (11): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (12): Conv1d(256, 512, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "     (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (14): ReLU()\n",
       "     (15): AdaptiveAvgPool1d(output_size=512)\n",
       "   )\n",
       "   (vertical_encoder): Sequential(\n",
       "     (0): Conv1d(1, 64, kernel_size=(64,), stride=(4,), padding=(30,))\n",
       "     (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (4): Conv1d(64, 128, kernel_size=(32,), stride=(2,), padding=(15,))\n",
       "     (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (6): ReLU()\n",
       "     (7): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (8): Conv1d(128, 256, kernel_size=(16,), stride=(2,), padding=(7,))\n",
       "     (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (10): ReLU()\n",
       "     (11): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "     (12): Conv1d(256, 512, kernel_size=(8,), stride=(2,), padding=(3,))\n",
       "     (13): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (14): ReLU()\n",
       "     (15): AdaptiveAvgPool1d(output_size=512)\n",
       "   )\n",
       "   (tacho_encoder): Sequential(\n",
       "     (0): Conv1d(1, 32, kernel_size=(64,), stride=(8,), padding=(28,))\n",
       "     (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): AdaptiveAvgPool1d(output_size=512)\n",
       "   )\n",
       "   (operational_encoder): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "     (3): ReLU()\n",
       "   )\n",
       "   (fusion): Sequential(\n",
       "     (0): Linear(in_features=2176, out_features=1024, bias=True)\n",
       "     (1): Dropout(p=0.3, inplace=False)\n",
       "     (2): ReLU()\n",
       "     (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "     (4): Dropout(p=0.3, inplace=False)\n",
       "     (5): ReLU()\n",
       "   )\n",
       "   (health_classifier): Linear(in_features=512, out_features=11, bias=True)\n",
       "   (confidence_head): Sequential(\n",
       "     (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "     (3): Sigmoid()\n",
       "   )\n",
       " ),\n",
       " (tensor([[-2.8454, -5.7267, -4.9249,  ...,  0.6260,  0.0153,  0.7158],\n",
       "          [ 2.2408,  0.8630,  0.5776,  ..., -1.2607, -2.3292, -0.3004],\n",
       "          [-2.2836, -0.3344, -0.6954,  ..., -0.1590,  1.3365, -0.6926],\n",
       "          ...,\n",
       "          [ 0.6854, -0.0389, -0.4131,  ...,  0.2038,  0.9623,  0.9045],\n",
       "          [ 0.9471, -1.7560, -1.2831,  ..., -0.2558, -0.2937,  1.2777],\n",
       "          [ 1.0873,  1.6477,  1.0789,  ..., -1.9442, -1.5122, -0.4019]]),\n",
       "  tensor([[-2.5539, -5.6430, -5.0973,  ...,  0.6919,  0.1602,  1.0743],\n",
       "          [ 0.3559, -1.2996,  1.3620,  ..., -0.8434,  0.4853, -0.7679],\n",
       "          [-2.3960, -0.7645, -0.7541,  ...,  0.4646, -0.7108,  1.0551],\n",
       "          ...,\n",
       "          [-0.6497, -0.5314,  0.2308,  ...,  1.6035,  1.5418,  0.4443],\n",
       "          [-1.5189,  0.8232,  1.8666,  ...,  1.4084,  0.5436, -0.7656],\n",
       "          [-0.8352, -0.9866, -1.1952,  ..., -0.5629,  0.3881,  0.6934]]),\n",
       "  tensor([[-2.4496, -5.6327, -4.6942,  ...,  0.8961,  0.0394,  0.8790],\n",
       "          [ 1.4263, -0.3538,  1.1240,  ..., -1.3139, -2.0474, -0.1082],\n",
       "          [-2.2644, -0.3490, -1.2736,  ...,  0.1730,  1.2975,  1.2300],\n",
       "          ...,\n",
       "          [-1.0630,  0.2050,  0.5654,  ...,  0.7463,  0.7799,  0.8417],\n",
       "          [-0.1543,  0.0864,  0.3064,  ...,  0.4641,  0.3374, -0.6806],\n",
       "          [ 0.6449, -1.0726, -1.6296,  ..., -1.1363, -1.7602, -1.8690]]),\n",
       "  tensor([[ 0.0036, -0.0304,  0.0036,  ..., -0.0304,  0.0036, -0.0304],\n",
       "          [-0.0111, -0.0156, -0.0111,  ..., -0.0157, -0.0111, -0.0156],\n",
       "          [-0.0119, -0.0149, -0.0119,  ..., -0.0149, -0.0119, -0.0149],\n",
       "          ...,\n",
       "          [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600],\n",
       "          [-0.0597, -0.0597, -0.0597,  ..., -0.0597, -0.0597, -0.0597],\n",
       "          [-0.0600, -0.0600, -0.0600,  ..., -0.0600, -0.0600, -0.0600]]),\n",
       "  tensor([[ 100.],\n",
       "          [ 100.],\n",
       "          [ 100.],\n",
       "          ...,\n",
       "          [3600.],\n",
       "          [3600.],\n",
       "          [3600.]]),\n",
       "  tensor([[ 50.],\n",
       "          [ 50.],\n",
       "          [ 50.],\n",
       "          ...,\n",
       "          [100.],\n",
       "          [100.],\n",
       "          [100.]]),\n",
       "  tensor([0, 0, 0,  ..., 8, 8, 8])))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
